ðŸ“˜ HuggingFace RAG App

A Retrieval-Augmented Generation (RAG) pipeline built using LangChain, FAISS, HuggingFace Inference API, and U.S. Census PDF documents.
This project demonstrates how to load PDFs, chunk them, embed them, build a vectorstore, and query them using a HuggingFace LLM.

ðŸš€ Features
âœ… PDF Loader

Loads multiple PDFs from the us_census/ directory using PyPDFDirectoryLoader.

âœ… Smart Chunking

Splits documents into overlapping chunks using
RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).

âœ… Vectorstore with FAISS

Efficient similarity search using FAISS and HuggingFace sentence embeddings.

âœ… RAG Chain

Combines:

a retriever

a custom prompt

a HuggingFace LLM
using LangChainâ€™s RunnablePassthrough.

âœ… HuggingFace Inference LLM

Works with any HF text-generation model like:
meta-llama/Llama-3.1-8B-Instruct

âœ… Clean, simple code in a Jupyter Notebook

Easy to follow, modify, and extend.